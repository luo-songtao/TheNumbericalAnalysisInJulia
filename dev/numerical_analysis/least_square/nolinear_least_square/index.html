<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>非线性最小二乘 · 数值分析(Julia语言描述)</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link href="../../../assets/logo.png" rel="icon" type="image/x-icon"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="数值分析(Julia语言描述) logo"/></a><div class="docs-package-name"><span class="docs-autofit">数值分析(Julia语言描述)</span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">总目录</a></li><li><span class="tocitem">求解一元方程</span><ul><li><a class="tocitem" href="../../equation_solving/">目录</a></li><li><a class="tocitem" href="../../equation_solving/bisect/">二分法</a></li><li><a class="tocitem" href="../../equation_solving/fixed_point_iteration/">不动点迭代法</a></li><li><a class="tocitem" href="../../equation_solving/newton_method/">牛顿方法</a></li><li><a class="tocitem" href="../../equation_solving/secant/">割线方法</a></li></ul></li><li><span class="tocitem">求解n元方程组</span><ul><li><a class="tocitem" href="../../equation_set/">目录</a></li><li><a class="tocitem" href="../../equation_set/gauss_elimination/">高斯消去法</a></li><li><a class="tocitem" href="../../equation_set/lu_factorization/">LU分解</a></li><li><a class="tocitem" href="../../equation_set/iteration_method/">迭代方法</a></li><li><a class="tocitem" href="../../equation_set/methods_about_SPD_matrix/">用于对称正定矩阵的方法</a></li><li><a class="tocitem" href="../../equation_set/nonlinear_equation_set/">非线性方程组</a></li></ul></li><li><span class="tocitem">插值多项式</span><ul><li><a class="tocitem" href="../../interpolation_polynomial/">目录</a></li><li><a class="tocitem" href="../../interpolation_polynomial/newton_difference_quotient/">牛顿差商</a></li><li><a class="tocitem" href="../../interpolation_polynomial/error_and_runge_phenomenon/">插值误差和龙格现象</a></li><li><a class="tocitem" href="../../interpolation_polynomial/chebyshev_interpolation/">切比雪夫插值</a></li><li><a class="tocitem" href="../../interpolation_polynomial/cubic_spline/">三次样条插值</a></li><li><a class="tocitem" href="../../interpolation_polynomial/bezier_curve/">贝塞尔曲线</a></li></ul></li><li><span class="tocitem">最小二乘</span><ul><li><a class="tocitem" href="../">目录</a></li><li><a class="tocitem" href="../normal_equation/">最小二乘与法线方程</a></li><li><a class="tocitem" href="../gram_schmidt_orthogon/">格拉姆-施密特正交</a></li><li><a class="tocitem" href="../least_square_and_qr/">最小二乘与QR分解</a></li><li><a class="tocitem" href="../householder_reflector/">豪斯霍尔德反射方法</a></li><li><a class="tocitem" href="../gmres/">广义最小余项方法(GMRES)</a></li><li class="is-active"><a class="tocitem" href>非线性最小二乘</a><ul class="internal"><li><a class="tocitem" href="#高斯牛顿法-1"><span>高斯牛顿法</span></a></li><li><a class="tocitem" href="#Levenberg-Marquardt方法-1"><span>Levenberg-Marquardt方法</span></a></li></ul></li></ul></li><li><span class="tocitem">数值微分与积分</span><ul><li><a class="tocitem" href="../../numerical_calculus/">目录</a></li><li><a class="tocitem" href="../../numerical_calculus/numerical_differential/">数值微分</a></li><li><a class="tocitem" href="../../numerical_calculus/numerical_integral/">数值积分</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">最小二乘</a></li><li class="is-active"><a href>非线性最小二乘</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>非线性最小二乘</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/luo-songtao/TheNumericalAnalysisInJulia/blob/master/docs/src/numerical_analysis/least_square/nolinear_least_square.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="非线性最小二乘-1"><a class="docs-heading-anchor" href="#非线性最小二乘-1">非线性最小二乘</a><a class="docs-heading-anchor-permalink" href="#非线性最小二乘-1" title="Permalink"></a></h1><ul><li><a href="#LeastSquare.gauss_newton-NTuple{4,Any}"><code>LeastSquare.gauss_newton</code></a></li><li><a href="#LeastSquare.levenberg_marquardt-NTuple{5,Any}"><code>LeastSquare.levenberg_marquardt</code></a></li></ul><h2 id="高斯牛顿法-1"><a class="docs-heading-anchor" href="#高斯牛顿法-1">高斯牛顿法</a><a class="docs-heading-anchor-permalink" href="#高斯牛顿法-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="LeastSquare.gauss_newton-NTuple{4,Any}" href="#LeastSquare.gauss_newton-NTuple{4,Any}"><code>LeastSquare.gauss_newton</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>高斯-牛顿方法</strong></p><pre><code class="language-none">gauss_newton(r, Dr, x_0, k)</code></pre><p>对于非线性最小二乘问题，可以使用高斯牛顿方法求解。</p><p><strong>高斯牛顿方法推导</strong></p><p>目的是最小化误差余项的平方和，对于m个方程和n个未知数的方程组，误差为:</p><p><span>$\qquad \begin{aligned} r_1(x_1, x_2, ..., x_n) &amp;= 0 \\ &amp; ... \\ r_m(x_1, x_2, ..., x_n) &amp;= 0 \end{aligned}$</span></p><p>误差平方和为：</p><div>\[E(x_1, ..., x_n) = \frac 12 (r^2_1+...+r^2_m)\]</div><p><strong>高斯牛顿方法推导源于牛顿法：</strong></p><p><span>$E(x)$</span>的二阶Taylor展开:</p><p><span>$\qquad \begin{aligned} E(x) \approx E(x_k) + E&#39;(x_k)(x-x_k) + \frac 12 E&#39;&#39;(x_k)(x-x_k)^2  \end{aligned}$</span></p><p>令<span>$\Delta x = x - x_k$</span>,即<span>$x = x_k + \Delta x$</span>:</p><p><span>$\qquad \begin{aligned} E(x_k+\Delta x) \approx E(x_k) + E&#39;(x_k)\Delta x + \frac 12 E&#39;&#39;(x_k){\Delta x}^2 \end{aligned}$</span></p><p>为了最小化E，也就是极值问题，因此令E的梯度为0:</p><p><span>$\qquad g(x_k) = \nabla E(x_k) = \frac {d}{d\Delta x}(E(x_k) + E&#39;(x_k)\Delta x + \frac 12 E&#39;&#39;(x_k){\Delta x}^2) = E&#39;(x_k) + E&#39;&#39;(x_k)\Delta x = 0$</span></p><p>则有：</p><p><span>$\Delta x = - \frac {E&#39;(x_k)}{E&#39;&#39;(x_k)}$</span></p><p>由于E是向量函数，这里将<span>$x_{k+1} = x_k + \Delta x$</span>改写为</p><div>\[x_{k+1} = x_k - H^{-1}g\]</div><p>其中g为梯度向量，H为海森矩阵</p><p><span>$\qquad \begin{aligned} g_j &amp;= 2\sum^m_{i=1}r_i \frac {\partial r_i}{\partial x_j} = 2\sum^m_{i=1}r_i J_{ij} \qquad &amp; j=1,2,...,n \\ h_{jk} &amp;= 2\sum^m_{i=1}(\frac{\partial r_i}{\partial x_j}\frac{\partial r_i}{\partial x_k} + \frac{\partial^2 r_i}{\partial x_j \partial x_k}) \approx 2\sum^m_{i=1} J_{ij} J_{ik} \qquad &amp; j,k=1,2,...,n \end{aligned}$</span></p><p>简化为:</p><p><span>$\qquad \begin{aligned} g &amp;= 2J^T_rr \\ H &amp;\approx 2J^T_rJ_r \end{aligned}$</span></p><p>其中<span>$J_r$</span>表示雅可比矩阵</p><div>\[x_{k+1} = x_k - (J^T_rJ_r)^{-1}J^T_rr(x_k)\]</div><p>同样为了避免求逆的过程，令<span>$H\Delta{x_k} = -g$</span>,即<span>$J^T_rJ_r \Delta{x_k} = -J^T_rr(x_k)$</span>，先求解出<span>$\Delta{x_k}$</span>, 然后代入<span>$x_{k+1} = x_k + \Delta{x_k}$</span>更新</p><p><strong>Example</strong></p><pre><code class="language-julia">function test_gauss_newton()
    # 找到一点，要求离三个圆的距离的平方和最小
    # 圆心坐标
    x1, y1 = -1, 0
    x2, y2 = 1, 0.5
    x3, y3 = 1, -0.5
    # 圆半径
    r1, r2, r3 = 1, 0.5, 0.5
    # 误差函数
    r = [
        (x,y) -&gt; sqrt((x-x1)^2+ (y-y1)^2) - r1
        (x,y) -&gt; sqrt((x-x2)^2+ (y-y2)^2) - r2
        (x,y) -&gt; sqrt((x-x3)^2+ (y-y3)^2) - r3
    ]
    # r关于(x,y)的一阶偏导数矩阵
    Dr = [
        (x,y) -&gt; (x-x1)/sqrt((x-x1)^2+ (y-y1)^2) (x,y) -&gt; (y-y1)/sqrt((x-x1)^2+ (y-y1)^2);
        (x,y) -&gt; (x-x2)/sqrt((x-x2)^2+ (y-y2)^2) (x,y) -&gt; (y-y2)/sqrt((x-x2)^2+ (y-y2)^2);
        (x,y) -&gt; (x-x3)/sqrt((x-x3)^2+ (y-y3)^2) (x,y) -&gt; (y-y3)/sqrt((x-x3)^2+ (y-y3)^2);
    ]
    x = round.(gauss_newton(r, Dr, [0;0], 10), digits=6)
    @assert reshape(x, 1,2) == [0.412891 0.0]
    return 
end</code></pre><pre><code class="language-julia-repl">julia&gt; test_gauss_newton()
2×1 Array{Float64,2}:
 0.412891
 0.0 </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/luo-songtao/TheNumericalAnalysisInJulia/blob/87bb16431303c38951b694198e97c35f24623eae/src/least_square/gauss_newton.jl#L1-L91">source</a></section></article><h2 id="Levenberg-Marquardt方法-1"><a class="docs-heading-anchor" href="#Levenberg-Marquardt方法-1">Levenberg-Marquardt方法</a><a class="docs-heading-anchor-permalink" href="#Levenberg-Marquardt方法-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="LeastSquare.levenberg_marquardt-NTuple{5,Any}" href="#LeastSquare.levenberg_marquardt-NTuple{5,Any}"><code>LeastSquare.levenberg_marquardt</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Levenberg Marquardt 方法</strong></p><pre><code class="language-none">levenberg_marquardt(r, Dr, x_0, k, λ)</code></pre><p>对于非线性最小二乘问题中，如果定义好的模型在计算得到了条件数比较差的雅可比矩阵的话，往往求出的解会有比较大的误差，因此 Levenberg Marquardt 方法使用了<strong>正则化</strong>来修复这个问题</p><p>其中用<span>$\lambda diag J^T_rJ_r$</span>来强化对角线元素的作用，以改善条件数</p><div>\[(J^T_rJ_r + \lambda diag J^T_rJ_r) \Delta{x_k} = -J^T_rr(x_k)\]</div><p>当<span>$\lambda = 0$</span>时，该方法就是高斯牛顿方法。另外<span>$\lambda$</span>通常看作一个常数，但该方法中常常使用不同的<span>$\lambda$</span>以适应问题，一般策略是：</p><ul><li>只要余下的平方误差和在每步降低，那么就使用一个因子降低<span>$\lambda$</span> </li><li>如果误差升高，则反之，使用因子升高<span>$\lambda$</span></li></ul><p><strong>Example</strong></p><p>使用Levenberg Marquardt将模型<span>$y = c_1 e^{-c_2(x-c_3)^2}$</span>拟合到数据点(1,3),(2,5),(2,7),(3,5),(4,1)</p><pre><code class="language-julia">function test_levenberg_marquardt()
    points = [
        (1,3)
        (2,5)
        (2,7)
        (3,5)
        (4,1)
    ]

    r = [(c1,c2,c3) -&gt; c1*exp(1)^(-c2*(x-c3)^2)-y for (x,y) in points]
    f_c1 = [(c1,c2,c3)-&gt; exp(1)^(-c2*(x-c3)^2) for (x,y) in points]
    f_c2 = [(c1,c2,c3)-&gt; -c1*(x-c3)^2*exp(1)^(-c2*(x-c3)^2) for (x,y) in points]
    f_c3 = [(c1,c2,c3)-&gt; 2c1*c2*(x-c3)*exp(1)^(-c2*(x-c3)^2) for (x,y) in points]
    Dr = hcat([f_c1,f_c2,f_c3]...)
    x = round.(levenberg_marquardt(r, Dr, [1;1;1], 1000, 50), digits=6)
    # x = round.(levenberg_marquardt(r, Dr, [1;1;1], 1000, 0), digits=6)   无法收敛
    @assert reshape(x, 1,3) == [6.300046 0.508648 2.248735]
    return x
end</code></pre><p>λ固定50，迭代1000步的收敛结果：</p><pre><code class="language-julia-repl">julia&gt; test_levenberg_marquardt()
3×1 Array{Float64,2}:
 6.300046
 0.508648
 2.248735</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/luo-songtao/TheNumericalAnalysisInJulia/blob/87bb16431303c38951b694198e97c35f24623eae/src/least_square/levenberg_marquardt.jl#L1-L50">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gmres/">« 广义最小余项方法(GMRES)</a><a class="docs-footer-nextpage" href="../../numerical_calculus/">目录 »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 20 February 2020 17:06">Thursday 20 February 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
